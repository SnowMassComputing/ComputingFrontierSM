\section{Computing for Perturbative QCD}
\label{chap:PQCD}
\subsection{Introduction}

One of the main challenges facing the particle physics community to date
is interpreting LHC measurements on the basis of accurate and
robust theoretical predictions.  The discovery of a Higgs-like
particle in Summer 2012~\cite{Aad:2012tfa,Chatrchyan:2012ufa} serves
as a remarkable example of the level of detail and accuracy that must
be achieved in order to enable a
discovery~\cite{Dittmaier:2011ti,Dittmaier:2012vm,Heinemeyer:2013tqa}.
Signals for the Higgs boson of the Standard Model (SM) are orders of 
magnitude smaller than their backgrounds at the LHC, and they are 
determined by quantum effects.  Detailed calculations are therefore 
mandatory, and they will become even more necessary as we further 
explore the Terascale at the full LHC design energy.

Providing precise theoretical predictions has been a priority of the U.S.\ 
theoretical particle physics community for many years, and has seen an
unprecedented boost of activity during the last ten years. With the
aim of extracting evidence of new physics from the data, theorists
have focused on reducing the systematic uncertainty of their predictions
by including strong (QCD) and electroweak (EW) effects at higher orders
in the perturbative expansion. This is particularly important as
beyond-Standard-Model effects are expected at roughly the TeV scale. 
Typical decay chains of potential new particles would involve many 
decay products, several of which can be massive. The SM backgrounds 
are complex processes which call for highly sophisticated calculational 
tools in order to provide realistic predictions.

We have reached a time when no conceptual problems block us
from being able to break next-to-leading order (NLO)
perturbative QCD calculations into standard modular steps and automate
them, making them available to the worldwide LHC community.  It is
implicit that such an effort will benefit greatly from a unified
environment in which calculations can be performed and data can be
exchanged freely between theorists and experimentalists,
as well as from the availability of adequate computational means
for extensive multiple analyses.

We see the frontier of perturbative
calculations for collider phenomenology being in the
development and optimization of next-to-next-to-leading order (NNLO)
QCD calculations, sometimes combined with EW corrections, and in the
study of more exclusive signatures that requires resummation 
of logarithmically enhanced higher-order corrections to all orders.
It is also conceivable that techniques for matching NNLO fixed-order 
calculations to parton-shower simulations will be constructed in the 
next five years. In all cases, the availability 
of extensive computational resources could be instrumental
in boosting the exploration of new techniques as well as in
obtaining very accurate theoretical predictions at a pace and in a
format that is immediately useful to the experiments.

\subsection{Results and recommendations}

This workshop provided a framework for implementing higher order  
calculations in a standardized computing environment made available 
by DOE at the National Energy Research Scientific Computing Center
(NERSC).  Resource requirements were determined for the
calculation of important background and signal reactions at the
LHC, including higher order QCD and EW effects. Prototypical results 
are listed in Table~\ref{tab:summary} and have been summarized in a 
white paper~\cite{HPCWP}.

Different High Performance Computing (HPC) environments were tested
during this workshop and their suitability for perturbative QCD calculations 
was assessed. We find that it would be beneficial to make the national HPC 
facilities ALCF, OLCF, and NERSC accessible to particle theorists and
experimentalists so they can use existing
calculational tools for experimental studies involving extensive
multiple runs without depending on the computer power and manpower
available to the code authors. Access to these facilities will also
allow prototyping the next generation of parallel computer programs
for QCD phenomenology and precision calculations.

The computation of NLO corrections in perturbative QCD has been entirely
automated. Resource requirements for NLO calculations determined during 
this workshop can thus be seen as a baseline that enables phenomenology 
during the LHC era. NNLO calculations are still performed 
on a case-by-case basis, and their computing needs can only be 
projected with a large uncertainty. It seems clear, however, that cutting-edge 
calculations will require access to leadership class computing facilities.

The use of HPC in perturbative QCD applications is currently in
an exploratory phase. We expect that the demand for access to HPC
facilities will continue to grow as more researchers realize the 
potential of parallel computing in accelerating scientific progress. 
At the same time, we expect growing demand for educating young researchers 
in cutting-edge computing technology. It would be highly beneficial 
to provide a series of topical schools and workshops related 
to HPC in HEP. They may be co-organized with experiments to foster 
the creation of a knowledge base.

Large-scale distributed computing in Grid environments 
may become relevant for perturbative QCD applications 
in the near future. This development will be accelerated if Computing Grids
can also provide access to HPC facilities and clusters where parallel 
computing is possible on a smaller scale. The Open Science Grid (OSG)
has taken first steps in this direction, and we have successfully used their
existing interface. The amount of training for new users could be minimized
if the OSG were to act as a front-end to the national HPC facilities
as well as conventional computing facilities.

\begin{table}
  \begin{tabular}{ccc}
    \hline
    Type of calculation & CPU hours per project & projects per year \\
    \hline\hline
    NLO parton level & 50,000 - 600,000 & 10-12\\
    NNLO parton level & 50,000 - 1,000,000 & 5-6\\
    Event generation & 50,000 - 250,000 & 5-8\\
    Matrix Element Method & $\sim$ 200,000 & 3-5\\
    Exclusive jet cross sections & $\sim$ 300,000 & 1-2\\
    Parton Distributions & $\sim$ 50,000 & 5-6\\
    \hline
  \end{tabular}
  \caption{Summary of computing requirements for typical projects
    carried out by the US community~\cite{HPCWP}.
    \label{tab:summary}}
\end{table}


%%%\begin{table}
%%%  \centering
%%%  \begin{tabular}{llrr}
%%%    \hline
%%%    Process & Ref. & \multicolumn{2}{c}{Requirements}\\
%%%    & & CPU [core~h] & Storage [GB] \\
%%%    \hline\hline
%%%    $pp\to W^\pm+5 jets$ & \cite{Bern:2013gka} & 600,000 & 1,500 \\
%%%    $pp\to W^\pm+4 jets$ & \cite{Berger:2010zx} & 100,000 & 200\\
%%%    $pp\to Z+4 jets$ & \cite{Ita:2011wn} & 200,000 & 200\\
%%%    $pp\to Z+3 jets$ & \cite{Berger:2010vm} & 50,000 & 100 \\
%%%    $pp\to 4 jets$ & \cite{Bern:2011ep} & 200,000 & 150\\
%%%    \hline
%%%  \end{tabular}
%%%  \caption{CPU and Storage requirements for calculations on the
%%%    list of important processes identified during the LesHouches
%%%    series of workshops~\cite{AlcarazMaestre:2012vp}.
%%%    Numbers assume cross-checks with at least two independent runs
%%%    and are reported for AMD Opteron\trademark processors running at 2.1~GHz.
%%%    Storage requirements are reported for Root NTuple files which can be used
%%%    to replicate the entire event analysis.
%%%  \label{tab:nlo_wishlist}}
%%%\end{table}
%%%
%%%\begin{table}
%%%  \centering
%%%  \begin{tabular}{llrr}
%%%    \hline
%%%    Process & Ref. & Requirements & CPU clock\\
%%%    & & CPU [core~h] & [GHz]\\
%%%    \hline\hline
%%%    $pp\to W/Z$ & \cite{Melnikov:2006di,Li:2012wna} & 50,000 & 2.67 \\
%%%    $pp\to H$ & \cite{Anastasiou:2005qj} & 50,000 & 2.67 \\
%%%    $pp\to t\bar{t}$ & \cite{Baernreuther:2012ws,Czakon:2013goa} & 1,000,000 & 2.27\\
%%%    $pp\to $ jets ($g$ only) & \cite{Ridder:2013mf} & 85,000 & 2.20 \\
%%%    $pp\to H+$jet ($g$ only) & \cite{Boughezal:2013uia} & 500,000 & 2.67 \\
%%%    \hline
%%%  \end{tabular}
%%%  \caption{Summary of computing requirements for NNLO calculations.
%%%    Numbers were obtained on Intel\registered Xeon\registered CPU's.
%%%    \label{tab:nnlo_requirements}}
%%%\end{table}
%%%
%%%\begin{table}
%%%  \centering
%%%  \begin{tabular}{llllr}
%%%    \hline
%%%    Process & \multicolumn{2}{c}{$N_{jet}$} & Ref. & CPU [core~h] \\
%%%    & NLO & LO & & \\
%%%    \hline\hline
%%%    $pp\to W^\pm+jets$ & $\le$2 & $\le$4 & \cite{Hoeche:2012yf} & 100,000 \\
%%%    $pp\to h+jets$ & $\le$2 & $\le$3 & \cite{Hoeche:2013xxx} & 150,000 \\
%%%    $pp\to t\bar{t}+jets$ & $\le$1 & $\le$2 & \cite{Hoeche:2013mua} & 250,000 \\
%%%    $pp\to l\bar{\nu}\bar{l}'\nu'$ & $\le$1 & $\le$2 & \cite{Cascioli:2013xxx} & 50,000 \\
%%%    \hline
%%%  \end{tabular}
%%%  \caption{Computing requirements for merged NLO simulations in
%%%    various benchmark processes, using the Sherpa event generator
%%%    and assuming cross-checks with at least two independent runs.
%%%    \label{tab:nlo_merging}}
%%%\end{table}



