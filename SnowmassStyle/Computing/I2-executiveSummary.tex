\section{Distributed Computing and Facility Infrastructures}

Powerful distributed computing and robust facility infrastructures are essential for continued progress of particle physics across the Energy, Intesity, and Cosmic Frontiers.  Experiment and theory require a combination of HTC and HPC systems.  The LHC experiments are the dominant consumers of HTC.  They have been and will continue to be well served by it.  Most Intensity Frontier experiments can also be supported by HTC.  HPC is needed for applications such as lattice QCD, accelerator design and R\&D, data analysis and synthetic maps, N-body and hydro-cosmology simulations, supernova modeling, and, more recently, perturbative QCD.  Historically, national centers have focused primarily on HPC, but these centers have begun to address HTC, and are interested in attracting scientists who need HTC.

Energy Frontier experiments face a growth in data that will make it a challenge to meet their needs.  Doing so is possible, but it requires near-constant funding of the Worldwide LHC Computing Grid (WLCG), greater efficiencies in resource usage, and the evolution of software to take advantage of multicore processor architectures.   These experiments should also pursue and take advantage of opportunistic resources, be they in commercial clouds (which are not currently viable and cost effective as purchased resources), university and lab computing centers, or elsewhere.  The experiments would also benefit from further engagement with national HPC centers.  The centers could provide resources to HEP experiments, and have support staff that could help port and integrate applications such as detector simulations that have not traditionally been used in HPC environments.

Intensity Frontier experiments have comparatively smaller computing needs.  There are no technical reasons why they could not be met.  Such experiments should  use resources available through the Open Science Grid (OSG) or at national computing centers.  They would benefit from a collective effort to gain access to resources and share software and training.

Cosmic Frontier experiments,  and the simulations required to interpret them, will need a large increase in HPC resources in the coming years, along with lattice QCD and accelerator design.  Demand for access to HPC across HEP frontiers is expected to exceed the amount of available resources.  HPC-based computations are needed to interpret results from a number of important HEP experiments, and to realize the scientific returns from the substantial investments in those experiments.  The NERSC report on HEP computing needs indicates a shortage of HPC resources by a factor of four by 2017.  While funding and technology development needed to sustain traditional HPC growth rates are uncertain, they must be maintained to support HEP science.  There are a number of applications within HEP that would benefit from exascale computing and a cadre of scientists eager to support efforts to reach that scale.

Distributed computing infrastructures, based at labs and universities, have been critical to the success of the Energy Frontier experiments, and should continue to be able to serve these and other applications even as experiments grow.  There are no show-stoppers seen scale increases, but various developments should be pursued to improve efficiency and ease of use.  Keeping sufficient staff support at a reasonable cost is a continuing concern; finding operational efficiencies could help address this.  Given that HEP is the largest user of distributed scientific computing, currently in the form of HTC on computing grids, members of the field must continue to take a leadership role in its development.

National centers play an important role in some aspects of computing, and HEP might be able to take advantage of an expanded role.  Experiments should explore the use of the HPC centers as part of their efforts to diversify their computing architectures.  These centers do have access to large, state-of-the-art resources, operational support and expertise in many areas of computing.

We expect that distributed computing and facility infrastructures will continue to play a vital role in enabling discovery science.

